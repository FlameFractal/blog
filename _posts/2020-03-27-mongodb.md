---
layout: post
title: MongoDB Performance
subtitle: Lessons from working with mongo
category: [learning] 
tags: [databases, mongodb]
secret: false
---

Related Posts
- [Mongodb Performance](/2020-03-27-mongodb)

## Table Of Contents
{:.no_toc}
---
- TOC
{:toc}

## Indexing

### Concepts 

These are generally common to most databases/storage-systems but the details are specific to MongoDB

- Index is a data structure that helps make querying a collection fast, usually is a BTree with pointers to data on disk
- Indexes are stored in memory (for obvious reasons), except if the index becomes too large to hold in memory.

- If a query can be supported by multiple indexes, the optimiser runs a test - index that finds 101 documents first wins
	- Optimiser caches this winning plan until 1000 documents added or a new index created
	- `explain` will always run the index selection algorithm again 
- `sort` stage quits when it uses memory more than 32MB, so if possible always support the query's sorting with an index too

- Generally, MongoDB uses one index to fulfill a query, except when
	- query has `$or`, each clause of `$or` may use a different index
	- query supports index intersection

- Stages:
	- `COLLSCAN` - scanning full collection documents on disk
	- `IXSCAN` - scanning keys of index 
	- `FETCH` - get documents from disk
	- `SORT/SORT_KEY_GENERATOR` - in memory sort / extracts a fields from db to be sorted later
	- `AND_SORTED/AND_HASH` - index intersection

- Types
	- Single
	- Compound
	- MultiKey
	- Sparse/Partial/Unique
	- Text/Wildcard/Geospatial/TTL



### Designing an index

One needs to know query access patterns on a collection to create best indexes.

- Indexing every field is an antipattern to be cogizant of. Always ensure indexes can fit in memory, remove unused (`indexStats`) or indexes with common predicates
- ESR predicate order rule of thumb - the compound index should have this order of predicates. use query predicates wisely to support as many query access patterns as possible. avioid redundant predicate indexes 
	- Equality
		- include fields that filter out atleast 90% of the documents
		- high cardinality first
	- Sort
		- same order/direction as query if multiple sorts applied
	- Range
		- include fields that filter out atleast 90% of the documents
		- low cardinality first
- Covered queries - if query projection matches index fields, it never needs to go on disk.
- Collation - match the collation of the queries to the collation of the index
- Use partial or sparse indexes (`partialFilterExpression`) if possible, because they reduces index sizes, minimising future updates
- Index intersection - one index should be pluggable in another, but low prio by optimiser

How to judge if the index you created actually works?

- Explain the query before index, create the index, explain the query. The results should be indicative of whether it's the best or there's still scope.
- Ideally, a best index is one where totalKeysExamined == nReturned, totalDocumentsExamined = 0 and no in-memory sort stage.

### Exceptions and Common Gotchas

- $nin and $ne queries are not very selective
- covered queries cannot include _id
- cannot use different indexes for the query and the sort if you want to avoid an in-memory sort
- sorting on an array indexed with a multikey index the query plan includes a blocking SORT stage	

### Examples

1. Query predicate/prefix

Imagining tree like data structure makes it easy to understand.

Suppose these following indexes

Index1 - firstname
Index2 - firstname, lastname
Index3 - firstname, lastname, age
Index4 - lastname, firstname

I1 shares query predicate of `firstname` with I2 and I3
I2 shares query predicate of `firstname, lastname` with I3
I4 here doesn't share any query predicate with the other Indexes

Suppose these following queries with equality filter condition based on the mentioned field

Query1 - find({firstname})
Query2 - find({firstname, lastname})
Query3 - find({lastname})
Query4 - find({age})



Q1 can be supported by I1, I2, I3


schema design for best index
- never create exponentially growing subdocuments
	- array elements under 10^4
- reads faster than writes
- soft deletes to save rebalancing the b/b+ tree

### Commands

- `db.collection.createIndex({},{})`
- `db.collection.getIndexes()`
- `db.collection.getIndexKeys()`
- `db.collection.dropIndex()`
- `db.collection.dropIndex()`
- `db.collection.aggregate([{$indexStats:{}}])`

### Resources

- https://www.mongodb.com/blog/post/performance-best-practices-indexing
- https://emptysqua.re/blog/optimizing-mongodb-compound-indexes/#fnref:1
- http://learnmongodbthehardway.com/schema/indexes/
- https://studio3t.com/knowledge-base/articles/mongodb-query-performance/#find-the-source-of-the-top-ten-slowest-queries
- basics https://github.com/linghuazaii/blog/wiki/The-Joy-of-Mongodb-Indexing


## Debugging slow mongodb / high cpu

- db.currentOp({secs_running: {$gte: 30}})
- db.setProfilingLevel(0, 1000), db.system.profile.find().sort({millis:-1}).limit(20)
- mongotop 30 --uri='', mongostat
- .explain(), .explain("executionStats"), .explain("allPlansExecution"), .hint({})
- db.collection.getPlanCache().clearPlansByQuery()
- db.collection.getPlanCache().listQueryShapes()
- db.vouchers.aggregate([{$indexStats:{}}])


## Solving slow mongodb / high cpu

- adding indexes
- removing in-memory sorting
- redo-ing expensive aggregation queries


