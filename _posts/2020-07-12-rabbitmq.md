---
layout: post
title: RabbitMQ
subtitle: FILL THIS UP
category: [drafts] 
bigimg: 
- "/img/*.jpg" : "draft image"
tags: [drafts]
secret: false
---

DRAFT  

## Table Of Contents
{:.no_toc}
---
- TOC
{:toc}


# RabbitMQ

## Reliability and Message Lifecycle

deadletter queue - unprocessed/failed messages
	- incident file
	- diagnosis
	- possible causes
		- queue full, ttl reached
		- transient error (mem glitch)
		- unprocessable data (fas gaya)
		- consumer bug
		- put msg back in original queue
		- 

poison queues
	- 


Create a dead letter queue on a queue by queue basis and send messages there that cannot be processed. 
But what do you do from there? 
Incident Response and Root Cause Diagnosis
  possible causes
    - The original queue was full
    - The message/queue TTL expired
    - It failed due to a transient error. 
    - It failed because it is unprocessable (bad data, message versioning issue, serialization error, business validation fails, etc)
    - It failed because of a bug in the consumer.
some automation that periodically puts messages back in the original queue.
ensure that this automation can keep track of the messages so unprocessable messages don't enter an infinite loop
Message Lifecycle
  - publishing
  - publish_failed
  - publish_failed_retry
  - publish_failed_retry_limit_reached
  - published
Do we retry, discard, send to a failed message queue?
failed messages carry with them all the information practically possible to diagnose the failure. 
  - The consumer application
  - The exception or error message
  - The server
  - The time
  - Who published the message
  - How many times has this message been processed?

Messages that get sent for a retry are sent to a delay exchange/queue where it waits for the time that the subscriber has dictated and then it is returned to the consumer queue.


Messages that are sent to the failed exchange are wrapped in a FailedEvent which gives some context to the failure. Failed messages are consumed and written to SQL Server.

Message Tracking
  - Message Lifecycle Id in headers
  - Routing Slip - lists the places it has been
    - Each entry can include: Application, Server, Time, Action etc. 

fixed or exponential back-off with your retries




RabbitMq
- exchange, routing, queues
- By default, messages are written to disk such that they survive a broker restart
- To guarantee delivery, uses message acknowledgements which also incurs a massive latency penalty.
- can lose messages in network partition situations
- provides CP out of CAP theorem
- ack
  - atleast once
  - atmost once
  - exactly once
- queues
  - quorum?
- consumers must be prepared to handle redeliveries and otherwise be implemented with idempotence in mind.
  - Redeliveries will have a special boolean property, redeliver, set to true by RabbitMQ



- durability - broker on restart will recreate (queues, exchanges)
- persistency - broker onr restart will requeue
- dead-letter - broker will ddl message if 
  - nack with requeue=false
  - message ttl expired
  - queue length exceeded
- prefetch - number of unacked messages that can be consumed (sliding window)




- persistency not set
- 0 retries, sent to ddl on single error
- most errors are timeouts and consumer errors


Links
- https://medium.com/codait/handling-failure-successfully-in-rabbitmq-22ffa982b60f
- https://engineering.nanit.com/rabbitmq-retries-the-full-story-ca4cc6c5b493?gi=eee2fb4f7868
- https://www.devbridge.com/articles/messaging-with-rabbitmq-in-node-js/
